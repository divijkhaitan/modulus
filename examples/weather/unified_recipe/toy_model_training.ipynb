{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from omegaconf import DictConfig, ListConfig, OmegaConf\n",
    "from tqdm import tqdm\n",
    "import xarray as xr\n",
    "from utils import get_filesystem\n",
    "OmegaConf.register_new_resolver(\"eval\", eval)\n",
    "from graphcast_datapipes import SeqZarrDatapipe_GraphCast\n",
    "from normalisation_wrapper import InputsAndResiduals\n",
    "\n",
    "from modulus.distributed import DistributedManager\n",
    "from graphcast_reordering import *\n",
    "from loss_weights import WeightedMSELoss, get_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alignment check passed: The indexed list matches the intended output list.\n",
      "Alignment check passed: The indexed list matches the intended output list.\n",
      "Alignment check passed: The indexed list matches the intended output list.\n",
      "Alignment check passed: The indexed list matches the intended output list.\n",
      "Alignment check passed: The indexed list matches the intended output list.\n",
      "Alignment check passed: The indexed list matches the intended output list.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_alignment(input_list, index_array, intended_output_list):\n",
    "    \"\"\"\n",
    "    Checks if applying an index array to an input list aligns with an intended output list.\n",
    "\n",
    "    Args:\n",
    "        input_list: The original list of features (e.g., ORIGINAL_ORDER_INPUTS_178).\n",
    "        index_array: The array of indices to apply to the input_list.\n",
    "        intended_output_list: The expected output list after applying the index_array.\n",
    "\n",
    "    Prints detailed information about mismatches, including feature names and indices.\n",
    "    Returns True if the lists align, False otherwise.\n",
    "    \"\"\"\n",
    "    # indexed_list = [input_list[i] for i in index_array if i < len(input_list)]  # Apply indexing\n",
    "    indexed_list = []\n",
    "    for i in index_array:\n",
    "        if i is not None and i < len(input_list):\n",
    "            indexed_list.append(input_list[i])\n",
    "        else:\n",
    "            indexed_list.append(('total_precipitation', ('time', 0)))\n",
    "    if len(indexed_list) != len(intended_output_list):\n",
    "        print(f\"Error: Length mismatch! Indexed list length: {len(indexed_list)}, Intended output length: {len(intended_output_list)}\")\n",
    "        return False\n",
    "\n",
    "    aligned = True\n",
    "    for i, (indexed_feature, intended_feature) in enumerate(zip(indexed_list, intended_output_list)):\n",
    "        if indexed_feature != intended_feature:\n",
    "            print(f\"Mismatch at index {i}:\")\n",
    "            print(f\"  Indexed feature: {indexed_feature} (from input index {index_array[i]})\")\n",
    "            print(f\"  Intended feature: {intended_feature}\")\n",
    "            aligned = False\n",
    "\n",
    "    if aligned:\n",
    "        print(\"Alignment check passed: The indexed list matches the intended output list.\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"Alignment check failed: There are mismatches between the indexed list and the intended output list.\")\n",
    "        return False\n",
    "check_alignment(ORIGINAL_ORDER_INPUTS_176, original_176_to_original_83, ORIGINAL_ORDER_OUTPUTS_83)\n",
    "check_alignment(ORIGINAL_ORDER_INPUTS_178, original_178_to_original_83, ORIGINAL_ORDER_OUTPUTS_83)\n",
    "check_alignment(reordered_features_178, reorder_178_to_original_178, ORIGINAL_ORDER_INPUTS_178)\n",
    "check_alignment(reordered_features_178, reorder_178_to_original_176, ORIGINAL_ORDER_INPUTS_176)\n",
    "check_alignment(reordered_features_176, reorder_176_to_original_176, ORIGINAL_ORDER_INPUTS_176)\n",
    "check_alignment(reordered_features_list_outputs_83, reorder_output_to_original_output, ORIGINAL_ORDER_OUTPUTS_83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saptarishi.dhanuka_asp25/miniconda3/envs/modulus/lib/python3.10/site-packages/modulus/distributed/manager.py:346: UserWarning: Could not initialize using ENV, SLURM or OPENMPI methods. Assuming this is a single process job\n",
      "  warn(\n",
      "/home/saptarishi.dhanuka_asp25/miniconda3/envs/modulus/lib/python3.10/site-packages/modulus/models/module.py:314: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "from modulus.models.graphcast.graph_cast_net import GraphCastNet\n",
    "DistributedManager.initialize()\n",
    "dist = DistributedManager()\n",
    "\n",
    "model = GraphCastNet(input_dim_grid_nodes=184, output_dim_grid_nodes=83)\n",
    "# model = Module.instantiate(\n",
    "#         {\n",
    "#             \"__name__\": cfg.model.name,\n",
    "#             \"__args__\": {\n",
    "#                 k: tuple(v) if isinstance(v, ListConfig) else v\n",
    "#                 for k, v in cfg.model.args.items()\n",
    "#             },  # TODO: maybe mobe this conversion to resolver?\n",
    "#         }\n",
    "#     )\n",
    "model = model.to(dist.device)\n",
    "model.load('../../../../gc_weights/graphcast_0.25_13.mdlus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2230969/1784091207.py:3: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  hydra.initialize(config_path=\"conf\")\n",
      "/home/saptarishi.dhanuka_asp25/miniconda3/envs/modulus/lib/python3.10/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'config': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "data = xr.open_zarr('unified_recipe_datasets/arco_era5.zarr')\n",
    "hydra.core.global_hydra.GlobalHydra.instance().clear()  # Clear previous hydra instances\n",
    "hydra.initialize(config_path=\"conf\")  \n",
    "cfg = hydra.compose(config_name=\"config\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = get_filesystem(\n",
    "        cfg.filesystem.type,\n",
    "        cfg.filesystem.key,\n",
    "        cfg.filesystem.endpoint_url,\n",
    "        cfg.filesystem.region_name,\n",
    "    )\n",
    "train_dataset_mapper = fs.get_mapper(cfg.curated_dataset.train_dataset_filename)\n",
    "val_dataset_mapper = fs.get_mapper(cfg.curated_dataset.val_dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datapipe = SeqZarrDatapipe_GraphCast(\n",
    "        file_mapping=val_dataset_mapper,\n",
    "        variable_groups=cfg.curated_dataset.variable_groups,\n",
    "        batch_size=cfg.validation.batch_size,\n",
    "        num_steps=cfg.validation.num_steps + cfg.training.nr_input_steps,\n",
    "        shuffle=False,\n",
    "        device=dist.device,\n",
    "        process_rank=dist.rank,\n",
    "        world_size=dist.world_size,\n",
    "        batch=cfg.datapipe.batch,\n",
    "        parallel=cfg.datapipe.parallel,\n",
    "        num_threads=cfg.datapipe.num_threads,\n",
    "        prefetch_queue_depth=cfg.datapipe.prefetch_queue_depth,\n",
    "        py_num_workers=cfg.datapipe.py_num_workers,\n",
    "        py_start_method=cfg.datapipe.py_start_method,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for j, data in tqdm(enumerate(val_datapipe)):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants = data[0]['constants']\n",
    "inputs_surface = data[0]['inputs_surface']\n",
    "inputs_pressure_levels = torch.reshape(data[0]['inputs_pressure_levels'], (cfg.validation.batch_size, cfg.validation.num_steps + cfg.training.nr_input_steps, 78, 721, 1440))\n",
    "forcings = data[0]['forcings'].permute((0, 1, 2, 4, 3))\n",
    "node_features = data[0]['node_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = (torch.concat((constants[0][0], forcings[0][0], inputs_surface[0][0], \n",
    "               inputs_pressure_levels[0][0], forcings[0][1], inputs_surface[0][1], \n",
    "               inputs_pressure_levels[0][1]), dim=-3))\n",
    "first_target = (torch.concat((constants[0][0], forcings[0][1], inputs_surface[0][1], \n",
    "               inputs_pressure_levels[0][1], forcings[0][2], inputs_surface[0][2], \n",
    "               inputs_pressure_levels[0][2]), dim=-3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Model Input:\n",
    "1. Subtract input mean \n",
    "2. Divide by input stddev\n",
    "\n",
    "\n",
    "To get next weather state: \n",
    "1. If target variable was a model input then multiply by the output stddev and add to corresponding input value. \n",
    "2. Else, multiply by input stddev and add input mean\n",
    "\n",
    "\n",
    "To get label for loss comparison from the next weather state to be pre-computed\n",
    "1. Get normalised input\n",
    "2. If target variable was a model input then subtract the corresponding input value to return to residual and divide by output stddev\n",
    "3. If target variable was not an input, subtract input mean and divide by input stddev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mean = xr.load_dataset('../../../../mean_by_level.nc')\n",
    "input_std = xr.load_dataset('../../../../stddev_by_level.nc')\n",
    "output_std = xr.load_dataset('../../../../diffs_stddev_by_level.nc')\n",
    "\n",
    "input_mean = input_mean.rename({'total_precipitation_6hr': 'total_precipitation'})\n",
    "input_std = input_std.rename({'total_precipitation_6hr': 'total_precipitation'})\n",
    "output_std = output_std.rename({'total_precipitation_6hr': 'total_precipitation'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "levels_by_order = []\n",
    "variable_weights = {\n",
    "    \"10m_u_component_of_wind\": 0.1,\n",
    "    \"10m_v_component_of_wind\": 0.1,\n",
    "    \"mean_sea_level_pressure\": 0.1,\n",
    "    \"total_precipitation\": 0.1,\n",
    "}\n",
    "per_variable_weight_mapping = {}\n",
    "for idx, variable in enumerate(ORIGINAL_ORDER_OUTPUTS_83):\n",
    "    if isinstance(variable, str):\n",
    "        name = variable\n",
    "        levels_by_order.append(None)\n",
    "    elif len(variable) == 2:\n",
    "        name, _ = variable\n",
    "        levels_by_order.append(None)\n",
    "    else:\n",
    "        name, _, level = variable\n",
    "        levels_by_order.append(int(level[1]))\n",
    "    if name in variable_weights.keys():\n",
    "        per_variable_weight_mapping[idx] = variable_weights[name]\n",
    "\n",
    "latitude = xr.open_zarr(cfg.curated_dataset.train_dataset_filename).coords['latitude'].values\n",
    "\n",
    "loss_weights = get_weights((83, len(latitude), forcings.shape[-1]), latitude, levels_by_order, per_variable_weight_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to('cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "criterion = WeightedMSELoss(loss_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrapped_model = InputsAndResiduals(model, input_std, input_mean, output_std, \n",
    "                                   ORIGINAL_ORDER_INPUTS_176, ORIGINAL_ORDER_OUTPUTS_83, \n",
    "                                   reorder_178_to_original_176, original_176_to_original_83, \n",
    "                                   reorder_178_to_original_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = wrapped_model(input.to('cpu'), forcings[0][2].to('cpu'), node_features[0][0].to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0015)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    targets_extracted_outputs = wrapped_model._outputs_from_input_tensor(first_target.to('cpu'), wrapped_model.outputs_from_full_input_order)        \n",
    "    inputs = input[..., wrapped_model.input_permutation, :, :].to('cpu') # Inputs now has size 176\n",
    "\n",
    "    norm_actual_residuals = wrapped_model._subtract_input_and_normalize_target(inputs, targets_extracted_outputs)\n",
    "    norm_predicted_residuals = wrapped_model._subtract_input_and_normalize_target(inputs, outputs.squeeze())\n",
    "            \n",
    "    loss = criterion(norm_predicted_residuals.squeeze(), norm_actual_residuals.squeeze())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_timestep_2 = (torch.concat((constants[0][0], forcings[0][2], inputs_surface[0][1], \n",
    "               inputs_pressure_levels[0][1], forcings[0][2], outputs.to('cuda').squeeze()[original_output_to_reorder_output]), dim=-3))\n",
    "second_target = (torch.concat((constants[0][0], forcings[0][2], inputs_surface[0][2], \n",
    "               inputs_pressure_levels[0][2], forcings[0][3], inputs_surface[0][3], \n",
    "               inputs_pressure_levels[0][3]), dim=-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs_2 = wrapped_model(input_timestep_2.to('cpu'), forcings[0][3].to('cpu'), node_features[0][0].to('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0023)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    targets_extracted_outputs_2 = wrapped_model._outputs_from_input_tensor(second_target.to('cpu'), wrapped_model.outputs_from_full_input_order)        \n",
    "    inputs_timestep_2 = input_timestep_2[..., wrapped_model.input_permutation, :, :].to('cpu') # inputs_timestep_2 now has size 176\n",
    "\n",
    "    norm_actual_residuals_2 = wrapped_model._subtract_input_and_normalize_target(inputs_timestep_2, targets_extracted_outputs_2)\n",
    "    norm_predicted_residuals_2 = wrapped_model._subtract_input_and_normalize_target(inputs_timestep_2, outputs.squeeze())\n",
    "            \n",
    "    loss = criterion(norm_predicted_residuals_2.squeeze(), norm_actual_residuals_2.squeeze())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "def interactive_image_comparison(array1, array2, title_array):\n",
    "    \"\"\"\n",
    "    Create an interactive plot that displays images from two arrays side by side.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    array1 : numpy.ndarray\n",
    "        First array of images with shape (n, height, width) or (n, height, width, channels)\n",
    "    array2 : numpy.ndarray\n",
    "        Second array of images with shape (n, height, width) or (n, height, width, channels)\n",
    "    title_array : list\n",
    "        List of strings to be used as titles\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    None : Displays the interactive plot in the notebook\n",
    "    \"\"\"\n",
    "    # Ensure arrays have the same number of images\n",
    "    if len(array1) != len(array2) or len(array1) != len(title_array):\n",
    "        raise ValueError(\"All input arrays must have the same length\")\n",
    "    \n",
    "    # Create function to update the plot\n",
    "    def update_plot(index):\n",
    "        \n",
    "        max1 = np.max(array1[index])\n",
    "        max2 = np.max(array2[index])\n",
    "        min1 = np.min(array1[index])\n",
    "        min2 = np.min(array2[index])\n",
    "        max_val = np.max((max1, max2))\n",
    "        min_val = np.min((min1, min2))\n",
    "        \n",
    "        # Create a figure with proper layout\n",
    "        fig = plt.figure(figsize=(14, 7))\n",
    "        \n",
    "        # Plot first image\n",
    "        ax1 = plt.subplot(1, 2, 1)\n",
    "        im1 = ax1.imshow(array1[index], vmin=min_val, vmax=max_val)\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        # Plot second image\n",
    "        ax2 = plt.subplot(1, 2, 2)\n",
    "        im2 = ax2.imshow(array2[index], vmin=min_val, vmax=max_val)\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        # Add a colorbar that applies to both images\n",
    "        cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])  # [left, bottom, width, height]\n",
    "        fig.colorbar(im2, cax=cbar_ax)\n",
    "        \n",
    "        # plt.tight_layout(rect=[0, 0, 0.9, 1])  # Adjust layout to make room for colorbar\n",
    "        plt.suptitle(title_array[index], fontsize=14)\n",
    "        plt.show()\n",
    "    \n",
    "    # Create widgets\n",
    "    slider = widgets.IntSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=len(title_array)-1,\n",
    "        step=1,\n",
    "        description='Image:',\n",
    "        continuous_update=False\n",
    "    )\n",
    "    \n",
    "    dropdown = widgets.Dropdown(\n",
    "        options=[(title, i) for i, title in enumerate(title_array)],\n",
    "        value=0,\n",
    "        description='Select:'\n",
    "    )\n",
    "    \n",
    "    # Create output widget to display the plot\n",
    "    output = widgets.Output()\n",
    "    \n",
    "    # Link the dropdown and slider\n",
    "    def on_dropdown_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            slider.value = change['new']\n",
    "    \n",
    "    def on_slider_change(change):\n",
    "        if change['type'] == 'change' and change['name'] == 'value':\n",
    "            dropdown.value = change['new']\n",
    "            with output:\n",
    "                output.clear_output(wait=True)\n",
    "                update_plot(change['new'])\n",
    "    \n",
    "    dropdown.observe(on_dropdown_change)\n",
    "    slider.observe(on_slider_change)\n",
    "    \n",
    "    # Display initial plot\n",
    "    with output:\n",
    "        update_plot(0)\n",
    "    \n",
    "    # Display widgets and output\n",
    "    display(widgets.HBox([slider, dropdown]))\n",
    "    display(output)\n",
    "\n",
    "# # Alternative version for matplotlib-only environments (like non-Jupyter environments)\n",
    "# def interactive_image_comparison_matplotlib(array1, array2, title_array):\n",
    "#     \"\"\"\n",
    "#     Create an interactive matplotlib plot that displays images from two arrays side by side.\n",
    "    \n",
    "#     Parameters:\n",
    "#     -----------\n",
    "#     array1 : numpy.ndarray\n",
    "#         First array of images with shape (n, height, width) or (n, height, width, channels)\n",
    "#     array2 : numpy.ndarray\n",
    "#         Second array of images with shape (n, height, width) or (n, height, width, channels)\n",
    "#     title_array : list\n",
    "#         List of strings to be used as titles\n",
    "        \n",
    "#     Returns:\n",
    "#     --------\n",
    "#     None : Displays the interactive plot in a matplotlib window\n",
    "#     \"\"\"\n",
    "#     if len(array1) != len(array2) or len(array1) != len(title_array):\n",
    "#         raise ValueError(\"All input arrays must have the same length\")\n",
    "    \n",
    "#     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "#     plt.subplots_adjust(bottom=0.25)\n",
    "    \n",
    "#     # Initial images\n",
    "#     img1 = ax1.imshow(array1[0])\n",
    "#     ax1.set_title(f\"Image 1: {title_array[0]}\")\n",
    "#     ax1.axis('off')\n",
    "    \n",
    "#     img2 = ax2.imshow(array2[0])\n",
    "#     ax2.set_title(f\"Image 2: {title_array[0]}\")\n",
    "#     ax2.axis('off')\n",
    "    \n",
    "#     # Add slider\n",
    "#     ax_slider = plt.axes([0.25, 0.1, 0.65, 0.03])\n",
    "#     slider = Slider(\n",
    "#         ax=ax_slider,\n",
    "#         label='Image Index',\n",
    "#         valmin=0,\n",
    "#         valmax=len(array1)-1,\n",
    "#         valinit=0,\n",
    "#         valstep=1\n",
    "#     )\n",
    "    \n",
    "#     # Create a custom dropdown-like widget\n",
    "#     # (matplotlib doesn't have a built-in dropdown, so we're approximating with buttons)\n",
    "#     class Dropdown(AxesWidget):\n",
    "#         def __init__(self, ax, labels, active=0):\n",
    "#             AxesWidget.__init__(self, ax)\n",
    "#             self.labels = labels\n",
    "#             self.active = active\n",
    "#             self.buttons = []\n",
    "#             self.cnt = 0\n",
    "            \n",
    "#             # Create a button for showing/hiding options\n",
    "#             self.main_button = Button(plt.axes([0.25, 0.05, 0.65, 0.03]), f\"Select: {labels[active]}\")\n",
    "#             self.shown = False\n",
    "#             self.observers = {}\n",
    "#             self.main_button.on_clicked(self._show_hide)\n",
    "            \n",
    "#         def _show_hide(self, event):\n",
    "#             if self.shown:\n",
    "#                 for b in self.buttons:\n",
    "#                     b.ax.set_visible(False)\n",
    "#                 self.shown = False\n",
    "#             else:\n",
    "#                 y_pos = 0.05\n",
    "#                 for i, label in enumerate(self.labels):\n",
    "#                     if not self.buttons:\n",
    "#                         button_ax = plt.axes([0.25, y_pos - 0.04 * (i + 1), 0.65, 0.03])\n",
    "#                         button = Button(button_ax, label)\n",
    "#                         self.buttons.append(button)\n",
    "#                         button.on_clicked(self._make_callback(i))\n",
    "#                     else:\n",
    "#                         self.buttons[i].ax.set_visible(True)\n",
    "#                 self.shown = True\n",
    "#             plt.draw()\n",
    "                    \n",
    "#         def _make_callback(self, index):\n",
    "#             def callback(event):\n",
    "#                 if self.active != index:\n",
    "#                     self.active = index\n",
    "#                     self.main_button.label.set_text(f\"Select: {self.labels[index]}\")\n",
    "#                     for b in self.buttons:\n",
    "#                         b.ax.set_visible(False)\n",
    "#                     self.shown = False\n",
    "#                     # Notify observers\n",
    "#                     for cid, func in self.observers.items():\n",
    "#                         func(index)\n",
    "#                 plt.draw()\n",
    "#             return callback\n",
    "            \n",
    "#         def on_changed(self, func):\n",
    "#             \"\"\"Register a callback to receive slider events.\"\"\"\n",
    "#             cid = self.cnt\n",
    "#             self.observers[cid] = func\n",
    "#             self.cnt += 1\n",
    "#             return cid\n",
    "            \n",
    "#     # Create dropdown\n",
    "#     ax_dropdown = plt.axes([0.1, 0.025, 0.8, 0.04])  # This is just a placeholder\n",
    "#     ax_dropdown.set_visible(False)  # Hide the actual axes\n",
    "#     dropdown = Dropdown(ax_dropdown, title_array)\n",
    "    \n",
    "#     # Update function\n",
    "#     def update(val):\n",
    "#         index = int(slider.val)\n",
    "#         img1.set_data(array1[index])\n",
    "#         img2.set_data(array2[index])\n",
    "#         ax1.set_title(f\"Image 1: {title_array[index]}\")\n",
    "#         ax2.set_title(f\"Image 2: {title_array[index]}\")\n",
    "#         fig.canvas.draw_idle()\n",
    "    \n",
    "#     def dropdown_update(index):\n",
    "#         slider.set_val(index)\n",
    "    \n",
    "#     slider.on_changed(update)\n",
    "#     dropdown.on_changed(dropdown_update)\n",
    "    \n",
    "#     plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78abccb838a941e08c1049432fd9de21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, continuous_update=False, description='Image:', max=82), Dropdown(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a130305e27345a8873465ae9af13f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_image_comparison(targets_extracted_outputs.squeeze().numpy(), outputs.squeeze().cpu().numpy(), ORIGINAL_ORDER_OUTPUTS_83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29102145444a4932b72ffcd4c27c4bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntSlider(value=0, continuous_update=False, description='Image:', max=82), Dropdown(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd90997e3a546c5a59c4910d06beb1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_image_comparison(targets_extracted_outputs_2.squeeze().numpy(), outputs_2.squeeze().cpu().numpy(), ORIGINAL_ORDER_OUTPUTS_83)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(model, constants, inputs, forcings, node_features, num_steps = 1):\n",
    "    # Get number of steps to unroll\n",
    "    if forcings.shape[0] < 3:\n",
    "        raise ValueError(\"Need forcings at at least 3 different timesteps to make predictions\")\n",
    "    max_steps = forcings.shape[0] - 2\n",
    "    model_pred_i_minus_1 = inputs[0]\n",
    "    model_pred_i_0 = inputs[1]\n",
    "    model_predicted = []\n",
    "    for i in range(min(num_steps, max_steps)):\n",
    "        # Create Input\n",
    "        input = torch.concat((constants, forcings[i], model_pred_i_minus_1.squeeze(), forcings[i+1], model_pred_i_0.squeeze()), dim=0)\n",
    "        \n",
    "        # Store Predictions and update next steps for rollout\n",
    "        model_pred_i_minus_1 = model_pred_i_0\n",
    "        model_pred_i_0 = model(input, forcings[i+2], node_features)[original_output_to_reorder_output]\n",
    "        model_predicted.append(model_pred_i_0)\n",
    "\n",
    "    # Stack predictions\n",
    "    model_predicted = torch.stack(model_predicted, dim=1)\n",
    "\n",
    "    return model_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unrolled_predictions = unroll(wrapped_model, constants.squeeze()[0].cpu(), torch.concat((inputs_surface, inputs_pressure_levels), dim=-3).squeeze().cpu(), \n",
    "#        forcings.squeeze().cpu(), node_features.squeeze()[0].cpu(), num_steps=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_forward(model, constants, inputs_surface, inputs_pressure_levels, forcings, node_features, num_steps = 1):\n",
    "    # Forward pass\n",
    "    combined_inputs = torch.concat((inputs_surface, inputs_pressure_levels), dim=-3)\n",
    "    with torch.no_grad:\n",
    "        net_predicted_variables = unroll(model, constants.squeeze()[0].cpu(), inputs.squeeze(), forcings[0].cpu(), node_features[0, 0].cpu(), num_steps=num_steps)\n",
    "\n",
    "        # l2 loss\n",
    "        label = combined_inputs[:num_steps][..., reorder_output_to_original_output, :, :]\n",
    "        loss = (torch.mean(torch.pow(net_predicted_variables - label)))\n",
    "    return loss, net_predicted_variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "modulus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
